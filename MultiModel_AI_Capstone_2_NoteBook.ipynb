{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **NAME : SWETHA KUMAR**\n",
        "# **CAPSTONE 2**\n",
        "---"
      ],
      "metadata": {
        "id": "v5YgJgTT3L4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Table of Contents**\n",
        "---\n",
        "**1.** [**AI Multi Model APP**](#Section1)<br>\n",
        "**2.** [**Streamlit Installation**](#Section2)<br>\n",
        "**3.** [**WriteFile Main Code**](#Section3)<br>\n",
        "**4.** [**LocalTunnel Installation**](#Section4)<br>\n",
        "**5.** [**Port Address**](#Section5)<br>\n",
        "**6.** [**Visualization with streamlit**](#Section6)<br>\n"
      ],
      "metadata": {
        "id": "jkvCsx6Eujb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a name = Section1></a>\n",
        "# **1. AI Multi Model APP**\n",
        "---"
      ],
      "metadata": {
        "id": "WFwtNgg_vl_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary objective of this project is to develop a centralized\n",
        "platform that allows users to access and interact with a diverse set of\n",
        "AI, ML, and DL models from a single, cohesive interface. This platform is\n",
        "designed to simplify the process of working with advanced pre-trained\n",
        "models from sources such as **Hugging Face** and APIs like Google\n",
        "Console and **Gemini**, enabling users to interact seamlessly with state-of\u0002the-art AI capabilities. Leveraging Streamlit for frontend development\n",
        "and Google Colab for deployment, the app is built to be accessible,\n",
        "efficient, and user-friendly, ensuring that users can interact with these\n",
        "models without extensive setup or technical barriers.\n",
        "Additionally, the platform incorporates key functionalities, including\n",
        "object detection, text classification, text generation, and **multilingual\n",
        "responses**, providing a comprehensive suite of AI tools that users can\n",
        "explore and experiment with. Through this project, the aim is to create\n",
        "a versatile and accessible tool that brings cutting-edge AI technology\n",
        "into the hands of a broader audience, fostering greater engagement and\n",
        "understanding of AI-driven applications.\n",
        "\n",
        "**For a more detailed explanation of the Sources used for this project, you can refer this guide:** [Hugging Face](https://huggingface.co/models), [Google Console](https://console.cloud.google.com/)"
      ],
      "metadata": {
        "id": "CHh-D2Qavpok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a name = Section2></a>\n",
        "# **2.Streamlit Installation**\n",
        "---"
      ],
      "metadata": {
        "id": "Big9iXPaxw9w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezeHsbZMUJj-",
        "outputId": "a9a4b12a-bd07-400a-d9c2-f3ea3099dd90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a name = Section3></a>\n",
        "# **3. WriteFile Main Code**\n",
        "---"
      ],
      "metadata": {
        "id": "5Ptx_CcTyJbL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFKnTXolUWUc",
        "outputId": "beac78fc-0152-4d2c-b929-4fd37f079ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlit_app.py\n",
        "\n",
        "# MAIN\n",
        "import os\n",
        "import io\n",
        "import streamlit as st\n",
        "import torch\n",
        "\n",
        "# Neural network library\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModel , pipeline, AutoModelForTableQuestionAnswering\n",
        "\n",
        "#PIL (Python Imaging Library): functionality for opening, manipulating, and drawing on images.\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "#enables sending GET, POST, and other HTTP requests to interact with APIs\n",
        "import requests\n",
        "\n",
        "#For regular expression and string manipulation\n",
        "import re\n",
        "\n",
        "#API calls to Hugging Face's\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "# for interacting with OpenAI's API to access various models\n",
        "from openai import OpenAI\n",
        "\n",
        "#to use Google Cloud's Translation API for translating text\n",
        "from google.cloud import translate_v2 as translate\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set page layout to 'wide'\n",
        "st.set_page_config(layout=\"wide\", page_title=\"Multi-Function Streamlit App\")\n",
        "\n",
        "# Set up session state to track model loading\n",
        "if \"model_loaded\" not in st.session_state:\n",
        "    st.session_state[\"model_loaded\"] = {\n",
        "        \"similarity\": False,\n",
        "        \"audio_classifier\": False,\n",
        "        \"table_qa\": False,\n",
        "        \"translator\" :False\n",
        "    }\n",
        "\n",
        "if \"first_load\" not in st.session_state:\n",
        "  st.session_state[\"first_load\"] = True\n",
        "  st.cache_data.clear()  # Clears cached data\n",
        "  st.cache_resource.clear()  # Clears cached resources (like loaded models)\n",
        "  st.toast(\"Cache cleared on first load.\")\n",
        "\n",
        "# Initialize session state to store conversation history\n",
        "if \"history\" not in st.session_state:\n",
        "    st.session_state[\"history\"] = []\n",
        "\n",
        "# Function to load models\n",
        "@st.cache_resource\n",
        "def load_similarity_model():\n",
        "  if not st.session_state[\"model_loaded\"][\"similarity\"]:\n",
        "    st.session_state[\"tokenizer\"] = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n",
        "    st.session_state[\"model\"] = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n",
        "    st.session_state[\"model_loaded\"][\"similarity\"] = True\n",
        "\n",
        "    return st.session_state['tokenizer'], st.session_state[\"model\"]\n",
        "\n",
        "@st.cache_resource\n",
        "def load_audio_classifier():\n",
        "  if not st.session_state[\"model_loaded\"][\"audio_classifier\"]:\n",
        "    st.session_state[\"pipe\"] = pipeline(\"audio-classification\", model=\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
        "    st.session_state[\"model_loaded\"][\"audio_classifier\"] = True\n",
        "    return st.session_state[\"pipe\"]\n",
        "\n",
        "@st.cache_resource\n",
        "def load_table_qa():\n",
        "  if not st.session_state[\"model_loaded\"][\"table_qa\"]:\n",
        "    model_name = \"google/tapas-large-finetuned-wtq\"\n",
        "    st.session_state[\"tokenizer\"] = AutoTokenizer.from_pretrained(model_name)\n",
        "    st.session_state[\"model\"] = AutoModelForTableQuestionAnswering.from_pretrained(model_name)\n",
        "    st.session_state[\"pipe\"]  = pipeline(\"table-question-answering\", model=model_name)\n",
        "    st.session_state[\"model_loaded\"][\"table_qa\"] = True\n",
        "    return st.session_state[\"tokenizer\"], st.session_state[\"model\"], st.session_state[\"pipe\"]\n",
        "\n",
        "@st.cache_resource\n",
        "def load_translate_client():\n",
        "  try:\n",
        "      client = translate.Client()\n",
        "      return client\n",
        "\n",
        "  except Exception as e:\n",
        "      st.error(f\"Error initializing translate client: {e}\")\n",
        "      return None\n",
        "\n",
        "\n",
        "\n",
        "def similarity(source_sentence, comparison_sentences,sim_tokenizer, sim_model):\n",
        "\n",
        "    # Mean Pooling - Take attention mask into account for correct averaging\n",
        "    def mean_pooling(model_output, attention_mask):\n",
        "        token_embeddings = model_output[0]\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "    def get_similarity(source_sentence, comparison_sentences):\n",
        "        sentences = [source_sentence] + comparison_sentences\n",
        "        encoded_input = sim_tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model_output = sim_model(**encoded_input)\n",
        "        embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "        source_embedding = embeddings[0]\n",
        "        similarity_scores = F.cosine_similarity(source_embedding, embeddings[1:]).tolist()\n",
        "\n",
        "        results = [[comparison_sentences[i], {similarity_scores[i]}] for i in range(len(comparison_sentences))]\n",
        "        results.sort( key=lambda x: x[1], reverse=True)\n",
        "        results = [[comparison_sentences[i], f\"{round(similarity_scores[i] * 100, 2)}%\"] for i in range(len(comparison_sentences))]\n",
        "        return results\n",
        "\n",
        "    return get_similarity(source_sentence, comparison_sentences)\n",
        "\n",
        "# Define the calculator function\n",
        "def calculator(num1, num2, operation):\n",
        "    if operation == 'Add':\n",
        "        return num1 + num2\n",
        "    elif operation == 'Subtract':\n",
        "        return num1 - num2\n",
        "    elif operation == 'Multiply':\n",
        "        return num1 * num2\n",
        "    elif operation == 'Divide':\n",
        "        return num1 / num2 if num2 != 0 else \"Cannot divide by zero\"\n",
        "\n",
        "def image_classifier(image):\n",
        "    # API details\n",
        "    API_URL = \"https://api-inference.huggingface.co/models/timm/resnet50.a1_in1k\"\n",
        "    headers = {\"Authorization\": \"Bearer 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\"}  # Replace with your actual token if needed\n",
        "\n",
        "    # Function to query the model\n",
        "    def query(image_data):\n",
        "        response = requests.post(API_URL, headers=headers, data=image_data)\n",
        "        if response.status_code == 200:\n",
        "            return [result[\"label\"] for result in response.json()]\n",
        "        else:\n",
        "            st.error(f\"Error: {response.status_code} - {response.text}\")\n",
        "            return []\n",
        "\n",
        "    return query(image)\n",
        "\n",
        "#Audio Classification:\n",
        "def audio_classifier(audio,audio_pipe):\n",
        "\n",
        "  def classify_audio(audio):\n",
        "      \"\"\"\n",
        "      Classifies an audio file and returns the top prediction.\n",
        "\n",
        "      Parameters:\n",
        "          audio_path (str): File path of the audio file provided by Streamlit.\n",
        "\n",
        "      Returns:\n",
        "          str: Label of the predicted class.\n",
        "      \"\"\"\n",
        "      # Perform classification\n",
        "      predictions = pipe(audio)\n",
        "\n",
        "      # Format predictions for output\n",
        "      return predictions[0]['label']\n",
        "\n",
        "  pipe = audio_pipe\n",
        "\n",
        "  return classify_audio(audio)\n",
        "\n",
        "#Table Q&A:\n",
        "def table_qa(table, question,qa_tokenizer, qa_model, qa_pipe):\n",
        "\n",
        "  def preprocess_table(table):\n",
        "      \"\"\"\n",
        "      Preprocesses the table by converting all cells to strings\n",
        "      and filling any missing values.\n",
        "      \"\"\"\n",
        "      return table.fillna(\"\").astype(str)\n",
        "\n",
        "  def answer_question(table, question):\n",
        "      \"\"\"\n",
        "      Answers a question based on the provided table.\n",
        "\n",
        "      Parameters:\n",
        "          table (pd.DataFrame): Data table in pandas DataFrame format.\n",
        "          question (str): Question about the table.\n",
        "\n",
        "      Returns:\n",
        "          str: Answer to the question.\n",
        "      \"\"\"\n",
        "      # Preprocess the table to ensure compatibility\n",
        "      table = preprocess_table(table)\n",
        "\n",
        "      # Use the pipeline to answer the question based on the table\n",
        "      try:\n",
        "          answer = pipe({\"table\": table.to_dict(orient=\"records\"), \"query\": question})\n",
        "          return answer[\"answer\"]\n",
        "      except Exception as e:\n",
        "          st.error(f\"An error occurred: {e}\")\n",
        "          return \"An error occurred during processing.\"\n",
        "\n",
        "  # Assign the loaded TAPAS model and tokenizer\n",
        "  pipe = qa_pipe\n",
        "  tokenizer = qa_tokenizer\n",
        "  model = qa_model\n",
        "\n",
        "  return answer_question(table, question)\n",
        "\n",
        "#Object Detection:\n",
        "def object_detection(image_data):\n",
        "  # Hugging Face API details\n",
        "  API_URL = \"https://api-inference.huggingface.co/models/facebook/detr-resnet-101\"\n",
        "  headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "  def query(image_data):\n",
        "      \"\"\"Sends image data to the Hugging Face API for object detection.\"\"\"\n",
        "      response = requests.post(API_URL, headers=headers, data=image_data)\n",
        "      if response.status_code == 200:\n",
        "          return response.json()  # Successful response\n",
        "      elif response.status_code == 503:\n",
        "          st.warning(\"Model is still loading. Retrying...\")\n",
        "          time.sleep(20)\n",
        "      else:\n",
        "          st.error(f\"Error: {response.status_code} - {response.text}\")\n",
        "          return None\n",
        "\n",
        "  def detect_objects(image):\n",
        "      \"\"\"Detects objects in the given image using the Hugging Face API.\"\"\"\n",
        "      # Save the uploaded image temporarily\n",
        "      image.save(\"temp_image.webp\")\n",
        "\n",
        "      # Read the saved image\n",
        "      with open(\"temp_image.webp\", \"rb\") as f:\n",
        "          image_data = f.read()\n",
        "\n",
        "      output = query(image_data)\n",
        "      return output\n",
        "  return detect_objects(image_data)\n",
        "\n",
        "# Text Generation\n",
        "def text_generation(prompt):\n",
        "\n",
        "  # Define your API key\n",
        "  API_KEY = 'AIzaSyCk3Ner-w3ffglU5VjqD7LQszqZj1_Zdwo'\n",
        "\n",
        "  def generate_text(prompt):\n",
        "      headers = {\n",
        "          'Content-Type': 'application/json',\n",
        "          }\n",
        "\n",
        "      data = {\n",
        "          \"contents\":\n",
        "           [{\"parts\":\n",
        "            [{\"text\":f\"{prompt}\"}]\n",
        "\n",
        "             }\n",
        "\n",
        "            ]\n",
        "\n",
        "          }\n",
        "      response = requests.post('https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=' + API_KEY\n",
        "      , headers=headers, json=data)\n",
        "      if response.status_code == 200:\n",
        "          return response.json()['candidates'][0]['content']['parts'][0]['text']\n",
        "      else:\n",
        "          return f\"Error: {response.status_code} - {response.text}\"\n",
        "\n",
        "  return generate_text(prompt)\n",
        "\n",
        "def translator(text,source_language,target_language):\n",
        "\n",
        "  # Define the translation function\n",
        "  def translate_text(text, source_language, target_language):\n",
        "      try:\n",
        "          # Convert human-readable language names to language codes\n",
        "          result = translate_client.translate(\n",
        "              text, target_language=languages[target_language], source_language=languages[source_language]\n",
        "          )\n",
        "          return result['translatedText']\n",
        "      except Exception as e:\n",
        "          return f\"Error during translation: {e}\"\n",
        "  return translate_text(text, source_language, target_language)\n",
        "\n",
        "# Chatbot\n",
        "def chatbot(user_message):\n",
        "  # Initialize the OpenAI client\n",
        "  client = OpenAI(\n",
        "      base_url=\"https://api-inference.huggingface.co/v1/\",\n",
        "      api_key=\"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\"\n",
        "  )\n",
        "\n",
        "  # Chatbot response function\n",
        "  def get_chatbot_response(user_message, history):\n",
        "      \"\"\"\n",
        "      Generates a response for the chatbot interface.\n",
        "\n",
        "      Parameters:\n",
        "          user_message (str): The latest user message.\n",
        "          history (list): Chat history containing previous interactions.\n",
        "\n",
        "      Returns:\n",
        "          list: Updated history including the model's response.\n",
        "      \"\"\"\n",
        "      # Prepare the conversation history for the model\n",
        "      messages = [{\"role\": \"user\", \"content\": user_message}]\n",
        "\n",
        "      # Stream model response\n",
        "      response_content = \"\"\n",
        "\n",
        "      try:\n",
        "          # Chat completions with streaming\n",
        "          stream = client.chat.completions.create(\n",
        "              model=\"mistralai/Mistral-Nemo-Instruct-2407\",\n",
        "              messages=messages,\n",
        "              max_tokens=500,\n",
        "              stream=True\n",
        "          )\n",
        "\n",
        "          # Accumulate response content from streamed chunks\n",
        "          for chunk in stream:\n",
        "              response_content += chunk.choices[0].delta.content\n",
        "\n",
        "          # Append user message and model response to history\n",
        "          history.append((user_message, response_content))\n",
        "\n",
        "      except Exception as e:\n",
        "          response_content = f\"An error occurred: {str(e)}\"\n",
        "          history.append((user_message, response_content))\n",
        "\n",
        "      return history\n",
        "\n",
        "  return get_chatbot_response(user_message, st.session_state.history)\n",
        "\n",
        "# Text to Image\n",
        "def text_to_image(prompt):\n",
        "  # Define the Hugging Face API endpoint and headers with your API key\n",
        "  API_URL = \"https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-3.5-large\"\n",
        "  headers = {\"Authorization\": \"Bearer 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\"}  # Replace with your actual token\n",
        "\n",
        "  # Function to call the Hugging Face model API\n",
        "  def generate_image(prompt):\n",
        "      payload = {\"inputs\": prompt}\n",
        "      response = requests.post(API_URL, headers=headers, json=payload)\n",
        "\n",
        "      if response.status_code == 200:\n",
        "          # Process the image content\n",
        "          image = Image.open(io.BytesIO(response.content))\n",
        "          return image\n",
        "      else:\n",
        "          st.error(f\"Error: {response.status_code} - {response.text}\")\n",
        "          return None\n",
        "\n",
        "  return generate_image(prompt)\n",
        "\n",
        "# Streamlit app layout\n",
        "st.title(\"Multi-Function Streamlit App\")\n",
        "\n",
        "# Option to select between Calculator and Sentence Similarity using tabs\n",
        "tab1, tab2, tab3, tab4, tab5, tab6 , tab7 , tab8 , tab9 , tab10 = st.tabs([\"Text Generation\", \"Sentence Similarity Checker\", \"Image Classification\",\"Audio Classification\",\"Table Question & Answering\",\"Object Detection\",\"Calculator\",\"Text Translator\",\"Chatbot\",\"Text to Image\"])\n",
        "\n",
        "# Define language codes\n",
        "languages = {\n",
        "  'English': 'en',\n",
        "  'German': 'de',\n",
        "  'Tamil': 'ta',\n",
        "  'Spanish': 'es',\n",
        "  'French': 'fr',\n",
        "  'Hindi': 'hi',\n",
        "  'Arabic': 'ar',\n",
        "  'Amharic': 'am',\n",
        "  'Aragonese': 'an',\n",
        "  'Armenian': 'hy',\n",
        "  'Albanian': 'sq',\n",
        "  'Azerbaijani': 'az',\n",
        "  'Bulgarian': 'bg',\n",
        "  'Chinese': 'zh',\n",
        "  'Croatian': 'hr',\n",
        "  'Czech': 'cs',\n",
        "  'Catalan': 'ca',\n",
        "  'Danish': 'da',\n",
        "  'Dutch': 'nl',\n",
        "  'Estonian': 'et',\n",
        "  'Filipino': 'tl',\n",
        "  'Finnish': 'fi',\n",
        "  'Galician': 'gl',\n",
        "  'Greek': 'el',\n",
        "  'Gujarati': 'gu',\n",
        "  'Hebrew': 'he',\n",
        "  'Italian': 'it',\n",
        "  'Icelandic': 'is',\n",
        "  'Japanese': 'ja',\n",
        "  'Korean': 'ko',\n",
        "  'Kannada': 'kn',\n",
        "  'Kyrgyz': 'ky',\n",
        "  'Hungarian': 'hu',\n",
        "  'Latvian': 'lv',\n",
        "  'Marathi': 'mr',\n",
        "  'Malayalam': 'ml',\n",
        "  'Mongolian': 'mn',\n",
        "  'Macedonian': 'mk',\n",
        "  'Nepali': 'ne',\n",
        "  'Norwegian': 'no',\n",
        "  'Polish': 'pl',\n",
        "  'Portuguese': 'pt',\n",
        "  'Punjabi': 'pa',\n",
        "  'Romanian': 'ro',\n",
        "  'Russian': 'ru',\n",
        "  'Serbian': 'sr',\n",
        "  'Sinhala': 'si',\n",
        "  'Slovak': 'sk',\n",
        "  'Slovenian': 'sl',\n",
        "  'Swedish': 'sv',\n",
        "  'Thai': 'th',\n",
        "  'Turkish': 'tr',\n",
        "  'Telugu': 'te',\n",
        "  'Ukrainian': 'uk',\n",
        "  'Urdu': 'ur',\n",
        "  'Uzbek': 'uz',\n",
        "  'Vietnamese': 'vi',\n",
        "  'Welsh': 'cy',\n",
        "  'Yiddish': 'yi',\n",
        "  'Zulu': 'zu'\n",
        "}\n",
        "\n",
        "# Gemini AI tab\n",
        "with tab1:\n",
        "  try:\n",
        "    # Streamlit app setup\n",
        "    st.title(\"Gemini AI Text Generation\")\n",
        "\n",
        "    json_file_name = '/content/my-project-8754-405207-4d68c3072fa8.json'\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = json_file_name\n",
        "    translate_client = load_translate_client()\n",
        "\n",
        "    # User input for prompt\n",
        "    prompt = st.text_area(\"Enter a prompt for text generation:\")\n",
        "\n",
        "    translate_checkbox = st.checkbox(\"Translate the generated text\")\n",
        "\n",
        "    if translate_checkbox:\n",
        "      source_language = st.selectbox(\"Source Language\", options=list(languages.keys()), index=list(languages.keys()).index(\"English\"), key ='selectbox3')\n",
        "      target_language = st.selectbox(\"Target Language\", options=list(languages.keys()), index=list(languages.keys()).index(\"Tamil\"), key ='selectbox4')\n",
        "\n",
        "    # Generate text button\n",
        "    if st.button(\"Generate Text\"):\n",
        "        with st.spinner(\"Generating...\"):\n",
        "            generated_text = text_generation(prompt)\n",
        "            if translate_checkbox:\n",
        "              generated_text = generated_text.replace('\\n\\n', '<PARAGRAPH>').replace('\\n', '<NEWLINE>')\n",
        "              translated_text = translator(generated_text, source_language, target_language)\n",
        "              translated_text = translated_text.replace('<PARAGRAPH>', '  \\n\\n').replace('<NEWLINE>', '  \\n')\n",
        "        if  translate_checkbox:\n",
        "          st.write(f\"### Generated Text in {target_language}:\")\n",
        "          st.markdown(translated_text, unsafe_allow_html=True)\n",
        "        else:\n",
        "          st.write(f\"### Generated Text:\")\n",
        "          st.markdown(generated_text)\n",
        "\n",
        "  except Exception as e:\n",
        "    st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "# Sentence Similarity Checker tab\n",
        "with tab2:\n",
        "  try:\n",
        "    st.header(\"Sentence Similarity Checker\")\n",
        "\n",
        "    with st.spinner(\"Loading model...\"):\n",
        "            sim_tokenizer, sim_model = load_similarity_model()\n",
        "\n",
        "    with st.form(\"similarity_form\"):\n",
        "      source_sentence = st.text_area(\"Source Sentence\", placeholder=\"Enter the source sentence...\")\n",
        "      comparison_sentences_input = st.text_area(\"Sentences to Compare\", placeholder=\"Enter sentences to compare, separated by new lines\")\n",
        "      if st.form_submit_button(\"Check Similarity\"):\n",
        "          if source_sentence and comparison_sentences_input:\n",
        "            with st.spinner(\"Finding Similarities...\"):\n",
        "              comparison_sentences = comparison_sentences_input.splitlines()\n",
        "              similarity_results = similarity(source_sentence, comparison_sentences,sim_tokenizer, sim_model)\n",
        "              st.write(\"### Similarity Scores:\")\n",
        "              for sentence, score in similarity_results:\n",
        "                  st.write(f\"**{sentence}**: {score}\")\n",
        "          else:\n",
        "              st.warning(\"Please enter both source and comparison sentences.\")\n",
        "\n",
        "  except Exception as e:\n",
        "    st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "# Image Classification tab\n",
        "with tab3:\n",
        "  try:\n",
        "    st.header(\"Image Classification with Hugging Face Model\")\n",
        "    st.markdown(\"Upload an image to classify using the ResNet50 model.\")\n",
        "\n",
        "    # Upload image\n",
        "    uploaded_file = st.file_uploader(\"Choose an image...\", type = [\"jpg\", \"jpeg\", \"png\",\"webp\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Open and display the image\n",
        "        image = Image.open(uploaded_file)\n",
        "        st.image(image, caption='Uploaded Image', width = 300)\n",
        "\n",
        "        # Convert image to bytes for the request\n",
        "        image_bytes = io.BytesIO()\n",
        "        image.save(image_bytes, format='WEBP')\n",
        "        image_bytes.seek(0)  # Seek to the start of the BytesIO buffer\n",
        "\n",
        "        # Get classification\n",
        "        if st.button(\"Classify Image\"):\n",
        "            with st.spinner(\"Classifying...\"):\n",
        "                results = image_classifier(image_bytes.read())\n",
        "                if results:\n",
        "                    st.success(\"Classification Results:\")\n",
        "                    for label in results:\n",
        "                        st.write(label)\n",
        "  except Exception as e:\n",
        "    st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "# Audio Classification:\n",
        "with tab4:\n",
        "  try:\n",
        "    st.title(\"Audio Classification with AST Model\")\n",
        "\n",
        "    with st.spinner(\"Loading model...\"):\n",
        "        audio_pipe = load_audio_classifier()\n",
        "\n",
        "    st.markdown(\"Upload an audio file to get predictions.\")\n",
        "\n",
        "    # Set up audio input\n",
        "    audio_input = st.file_uploader(\"Upload Audio\", type=[\"mp3\", \"wav\", \"ogg\"])\n",
        "\n",
        "    if audio_input is not None:\n",
        "        # Save the uploaded file temporarily\n",
        "        audio_path = f\"temp_audio.{audio_input.name.split('.')[-1]}\"\n",
        "        with open(audio_path, \"wb\") as f:\n",
        "            f.write(audio_input.read())\n",
        "\n",
        "        # Add a button to classify the audio\n",
        "        if st.button(\"Classify Audio\"):\n",
        "            with st.spinner(\"Classifying...\"):\n",
        "                prediction = audio_classifier(audio_path, audio_pipe)\n",
        "                st.success(f\"Predicted Label: {prediction}\")\n",
        "  except Exception as e:\n",
        "    st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "#Table Question & Answering:\n",
        "with tab5:\n",
        "  try:\n",
        "    # Streamlit Interface\n",
        "    st.title(\"Table Question Answering with TAPAS Model\")\n",
        "    with st.spinner(\"Loading model...\"):\n",
        "        qa_tokenizer, qa_model, qa_pipe = load_table_qa()\n",
        "\n",
        "    # Table upload or data entry\n",
        "    uploaded_file = st.file_uploader(\"Upload a CSV file containing the table data\")\n",
        "    if uploaded_file:\n",
        "        table_data = pd.read_csv(uploaded_file)\n",
        "    else:\n",
        "        st.warning(\"Please upload a CSV file.\")\n",
        "\n",
        "    if uploaded_file:\n",
        "        st.write(\"### Table Data\")\n",
        "        st.dataframe(table_data)\n",
        "\n",
        "        # Question input\n",
        "        question = st.text_input(\"Enter your question about the table:\")\n",
        "\n",
        "        # Display the answer\n",
        "        if st.button(\"Get Answer\"):\n",
        "            if question:\n",
        "                with st.spinner(\"Processing...\"):\n",
        "                    answer = table_qa(table_data, question ,qa_tokenizer, qa_model, qa_pipe)\n",
        "\n",
        "                    st.success(f\"Answer: {answer}\")\n",
        "            else:\n",
        "                st.warning(\"Please enter a question.\")\n",
        "  except Exception as e:\n",
        "      st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "# Object Detection:\n",
        "with tab6:\n",
        "  try:\n",
        "    # Streamlit app layout\n",
        "    st.title(\"Object Detection with DETR Model\")\n",
        "\n",
        "    def draw_boxes(image, boxes, scores, labels, threshold=0.5):\n",
        "      draw = ImageDraw.Draw(image)\n",
        "      for i, (box, score) in enumerate(zip(boxes, scores)):\n",
        "          if score >= threshold:\n",
        "              xmin, ymin, xmax, ymax = box\n",
        "              draw.rectangle([xmin, ymin, xmax, ymax], outline=\"red\", width=3)\n",
        "              draw.text((xmin, ymin), f\"{labels[i]}: {score:.2f}\", fill=\"red\")\n",
        "      return image\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Upload an image...\", type=[\"jpg\", \"jpeg\", \"png\",\"webp\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        image = Image.open(uploaded_file)\n",
        "        st.image(image, caption='Uploaded Image', width = 300)\n",
        "\n",
        "        if st.button(\"Detect Objects\"):\n",
        "            with st.spinner(\"Detecting objects...\"):\n",
        "                results = object_detection(image)\n",
        "\n",
        "                if results and isinstance(results, list):\n",
        "                    boxes, scores, labels = [], [], []\n",
        "                    for obj in results:\n",
        "                        if \"box\" in obj and \"score\" in obj and \"label\" in obj:\n",
        "                          if obj[\"score\"] >= 0.7:\n",
        "                            box = obj[\"box\"]\n",
        "                            score = obj[\"score\"]\n",
        "                            label = obj[\"label\"]\n",
        "                            boxes.append([box[\"xmin\"], box[\"ymin\"], box[\"xmax\"], box[\"ymax\"]])\n",
        "                            scores.append(score)\n",
        "                            labels.append(label)\n",
        "\n",
        "                    # Draw boxes on the image\n",
        "                    image_with_boxes = draw_boxes(image, boxes, scores, labels)\n",
        "                    st.image(image_with_boxes, caption='Detected Objects', use_column_width=True)\n",
        "\n",
        "                    st.write(\"### Detected Objects:\")\n",
        "                    for label, score in zip(labels, scores):\n",
        "                        if score >= 0.7:\n",
        "                            st.write(f\"**Label:** {label}, **Score:** {score:.2f}\")\n",
        "                else:\n",
        "                    st.error(\"Unexpected API response format. Please check the response structure.\")\n",
        "\n",
        "\n",
        "  except Exception as e:\n",
        "    st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "# Calculator\n",
        "with tab7:\n",
        "  try:\n",
        "    st.header(\"Calculator\")\n",
        "    with st.form(\"calculator_form\"):\n",
        "        num1 = st.number_input(\"Enter first number\", value=0.0)\n",
        "        num2 = st.number_input(\"Enter second number\", value=0.0)\n",
        "        operation = st.selectbox(\"Select operation\", [\"Add\", \"Subtract\", \"Multiply\", \"Divide\"])\n",
        "        calculate_button = st.form_submit_button(\"Calculate\")\n",
        "        if calculate_button:\n",
        "          with st.spinner(\"Calculating...\"):\n",
        "            result = calculator(num1, num2, operation)\n",
        "            st.write(f\"Result: {result}\")\n",
        "  except Exception as e:\n",
        "    st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "# Translator\n",
        "with tab8:\n",
        "  try:\n",
        "\n",
        "    # Streamlit UI\n",
        "    st.title(\"Text Translator\")\n",
        "    st.write(\"Translate text from one language to another using Google Cloud Translate API.\")\n",
        "\n",
        "    json_file_name = '/content/my-project-8754-405207-4d68c3072fa8.json'\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = json_file_name\n",
        "    translate_client = load_translate_client()\n",
        "\n",
        "    # Input fields\n",
        "    text = st.text_area(\"Text to Translate\")\n",
        "    source_language = st.selectbox(\"Source Language\", options=list(languages.keys()), index=list(languages.keys()).index(\"English\"), key ='selectbox1')\n",
        "    target_language = st.selectbox(\"Target Language\", options=list(languages.keys()), index=list(languages.keys()).index(\"Tamil\"), key ='selectbox2')\n",
        "\n",
        "    # Button to trigger translation\n",
        "    if st.button(\"Translate\"):\n",
        "        if translate_client is None:\n",
        "            st.error(\"Google Translate client initialization failed.\")\n",
        "        elif not text:\n",
        "            st.warning(\"Please enter text to translate.\")\n",
        "        else:\n",
        "          with st.spinner(\"Translating...\"):\n",
        "            translated_text = translator(text, source_language, target_language)\n",
        "            st.subheader(\"Translated Text\")\n",
        "            st.write(translated_text)\n",
        "\n",
        "  except Exception as e:\n",
        "    st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "# Chatbot\n",
        "with tab9:\n",
        "  try:\n",
        "    # Initialize Streamlit app layout\n",
        "    st.title(\"Chatbot with Mistral-Nemo Model\")\n",
        "    st.markdown(\"This is a chatbot interface powered by the Mistral-Nemo model.\")\n",
        "\n",
        "    # Temporary variable to hold the input message\n",
        "    if \"temp_input\" not in st.session_state:\n",
        "        st.session_state.temp_input = \"\"\n",
        "\n",
        "    # Input field for user message\n",
        "    user_message = st.text_input(\"Ask anything...\", key=\"input_message\")\n",
        "\n",
        "    # Handle user message submission\n",
        "    if st.button(\"Send\"):\n",
        "        if user_message:\n",
        "            # Call chatbot function\n",
        "            history = chatbot(user_message)\n",
        "\n",
        "            # Clear the temporary input state after sending\n",
        "            st.session_state.temp_input = \"\"\n",
        "\n",
        "            # Display chat history\n",
        "            st.write(\"### Chat History\")\n",
        "            for user_msg, bot_resp in history:\n",
        "                st.write(f\"**User:** {user_msg}\")\n",
        "                st.write(f\"**Bot:** {bot_resp}\")\n",
        "        else:\n",
        "            st.warning(\"Please enter a message.\")\n",
        "\n",
        "  except Exception as e:\n",
        "    st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "# Text to Image\n",
        "with tab10:\n",
        "  try:\n",
        "    # Streamlit UI\n",
        "    st.title(\"Text-to-Image Generation App\")\n",
        "    st.write(\"Generate images from text prompts using Stable Diffusion 3.5 (powered by Hugging Face API).\")\n",
        "\n",
        "    # Text input for the prompt\n",
        "    prompt = st.text_input(\"Enter a description (e.g., 'Astronaut riding a horse')\")\n",
        "\n",
        "    # Generate button\n",
        "    if st.button(\"Generate Image\"):\n",
        "        with st.spinner(\"Generating image...\"):\n",
        "            generated_image = text_to_image(prompt)\n",
        "\n",
        "            if generated_image:\n",
        "                st.image(generated_image, caption=\"Generated Image\", use_column_width=True)\n",
        "            else:\n",
        "                st.error(\"Failed to generate image.\")\n",
        "  except Exception as e:\n",
        "    st.error(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a name = Section4></a>\n",
        "# **4. LocalTunnel Installation**\n",
        "---"
      ],
      "metadata": {
        "id": "LmNDgQEgyZsV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5NDuwSiUvcv",
        "outputId": "e3777f45-4415-44d7-dae7-24b39bf41d06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "added 22 packages, and audited 23 packages in 5s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "1 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerability\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n"
          ]
        }
      ],
      "source": [
        "!npm install -g localtunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a name = Section5></a>\n",
        "# **5. Port Address**\n",
        "---"
      ],
      "metadata": {
        "id": "NegZLZiiywUE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZqUSI2rUy6a",
        "outputId": "6bbf6160-c643-421b-cf8c-73fd4f71adbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.106.200.249\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<a name = Section6></a>\n",
        "# **6. Visualization**\n",
        "---"
      ],
      "metadata": {
        "id": "nMhVY-IZy9Kp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhhPM3jZU1Q5",
        "outputId": "37a63512-1872-41a7-c965-9deafc17a371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.106.200.249:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://polite-cities-fetch.loca.lt\n",
            "2024-11-05 09:10:52.286680: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-05 09:10:52.314823: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-05 09:10:52.323684: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-05 09:10:52.343516: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-05 09:10:54.084802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "tokenizer_config.json: 100% 352/352 [00:00<00:00, 2.13MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 2.43MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 3.29MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 526kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "config.json: 100% 615/615 [00:00<00:00, 3.78MB/s]\n",
            "model.safetensors: 100% 133M/133M [00:00<00:00, 180MB/s]\n",
            "config.json: 100% 26.8k/26.8k [00:00<00:00, 72.5MB/s]\n",
            "model.safetensors: 100% 346M/346M [00:05<00:00, 58.4MB/s]\n",
            "preprocessor_config.json: 100% 297/297 [00:00<00:00, 1.90MB/s]\n",
            "tokenizer_config.json: 100% 490/490 [00:00<00:00, 2.81MB/s]\n",
            "config.json: 100% 1.66k/1.66k [00:00<00:00, 8.60MB/s]\n",
            "vocab.txt: 100% 262k/262k [00:00<00:00, 34.8MB/s]\n",
            "special_tokens_map.json: 100% 154/154 [00:00<00:00, 784kB/s]\n",
            "model.safetensors: 100% 1.35G/1.35G [00:18<00:00, 73.5MB/s]\n",
            "TAPAS models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version. Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "2024-11-05 09:11:36.826 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "/usr/local/lib/python3.10/dist-packages/streamlit/watcher/local_sources_watcher.py:210: UserWarning: Torchaudio's I/O functions now support par-call bakcend dispatch. Importing backend implementation directly is no longer guaranteed to work. Please use `backend` keyword with load/save/info function, instead of calling the udnerlying implementation directly.\n",
            "  lambda m: list(m.__path__._path),\n",
            "2024-11-05 09:29:27.403 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2024-11-05 09:34:49.138 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"
          ]
        }
      ],
      "source": [
        "!streamlit run streamlit_app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIQSBGbiVCDE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}